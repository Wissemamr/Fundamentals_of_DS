{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <h1>Principal component analysis (PCA) </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u> Exercise 02 </u>:\n",
    "Consider the following dataset composed of 6 data rows and 3 variables.\n",
    "\n",
    "|             |   x  |  y   |   z  | \n",
    "| ----------- | ---- | ---- | ---- |\n",
    "| R1          | 12   | 24   | 6    |\n",
    "| R2          | 17   | 15.5 | -2   |\n",
    "| R3          | 12   | 13   | 3    |\n",
    "| R4          | 6    | 13.5 | -2.5 |\n",
    "| R5          | 17   | 21   | 7.2  |\n",
    "| R6          | 4    | 20.3 | -0.9 |\n",
    "\n",
    "\n",
    "Your task is to extract a reduced set of features using PCA method. PCA\n",
    "provides a matrix of eigenvectors that explains the variance of the original\n",
    "variables. To reduce data using PCA, we run the next operation: <br>\n",
    "$$ R= X V $$\n",
    "Where, $R$ is the reduced data ($R$ has the shape of $r$ data rows, and $m$\n",
    "data columns), $X$ is the original data matrix (i.e., it has the shape of $r$\n",
    "data rows, and n columns). $V$ is the eigenvectors matrix (it has the\n",
    "shape of $n$ data rows, and $m$ data columns). <br>\n",
    "To calculate the reduction matrix $V$, we follow the next steps :\n",
    "1. Calculate the mean and standard deviation for each variable $ (X, Y, Z)$.\n",
    "\n",
    "2. Standardize the data using the $Z-score$ to get the standardized matrix $S$. Next, the $Z-score$ formula.\n",
    "\n",
    "$$\n",
    "\\text{Z-score} = \\frac{x - \\mu}{\\sigma}\n",
    "$$\n",
    "Where, $x$ is a feature vector,  $\\mu$  is the mean of\n",
    "$x$ and $\\sigma$ is standard deviation of $x$\n",
    "\n",
    "3. Calculate the covariance matrix, $C$, ($i.e.$, $C$ has the shape of $(n,n)$. The covariance matrix is given by:\n",
    "$$\n",
    "C(x, y) = \\text{Cov}(x, y) = \\frac{xy}{n-1}\n",
    "$$\n",
    "\n",
    "Where $x$ and $y$ are two feature vectors, and $n$ is the number of elements in\n",
    "the data vectors ($i.e.$, number of variables).\n",
    "\n",
    "4. Find the eigenvalues $(λ1, λ2 ,λ3)$ and corresponding eigenvectors $(v1\n",
    ",v2,v3)$ of the covariance matrix by solving the next equation:\n",
    "$$\n",
    "det(C- D)=0\n",
    "$$\n",
    "Where, $D$ is a diagonal matrix having in its diagonal $(λ1, λ2 ,λ3...)$ values.\n",
    "\n",
    "Also, to get the eigenvectors corresponding to the given eigenvalue\n",
    "$λ_i$, we solve the next linear equation:\n",
    "$$\n",
    "(C−λ_iI) v_i=0\n",
    "$$\n",
    "Where, $I$ is the identity matrix of shape $(n,n)$, and $v_i$ is the eigenvector\n",
    "of shape $(1,n)$ corresponding to the eigenvalue $λ_i$.\n",
    "\n",
    "5. Sort the eigenvalues in descending order and arrange the\n",
    "corresponding eigenvectors accordingly.\n",
    "6. Decide how many principal components to keep based on the\n",
    "explained variance ($i.e.$, each eigenvalue explains a portion of\n",
    "variance.). You can decide to keep, for example, the first two principal\n",
    "components if their sum represents $90\\%$ of the variance (sum of their\n",
    "eigenvalues divided on the total sum is bigger than $0.9$ ).\n",
    "\n",
    "7. Form the projection matrix $V$ by only keeping eigenvectors\n",
    "corresponding to the highest eigenvalues.\n",
    "8. Calculate the reduced data matrix $R$ by projecting the standardized data $X$ into the selected principal components to obtain the reduced-\n",
    "dimensional representation using."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
